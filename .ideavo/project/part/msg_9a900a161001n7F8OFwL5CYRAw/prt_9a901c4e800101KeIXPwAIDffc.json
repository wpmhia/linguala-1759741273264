{
  "id": "prt_9a901c4e800101KeIXPwAIDffc",
  "messageID": "msg_9a900a161001n7F8OFwL5CYRAw",
  "sessionID": "ses_65b8a18f2ffeMlgQ4UP0yHPHsm",
  "type": "tool",
  "tool": "write",
  "callID": "toolu_01FR8Vqn8aAkPWz29Ai2tgMa",
  "state": {
    "status": "completed",
    "input": {
      "filePath": "/home/user/project/lib/document-processors/docx-processor.ts",
      "content": "import mammoth from 'mammoth'\nimport { Document, Packer, Paragraph, TextRun, AlignmentType } from 'docx'\nimport { fileTypeFromBuffer } from 'file-type'\n\nexport interface DocxProcessingResult {\n  text: string\n  html: string\n  metadata: {\n    wordCount: number\n    characterCount: number\n  }\n  segments: Array<{\n    text: string\n    type: 'paragraph' | 'heading' | 'list'\n    level?: number\n  }>\n}\n\nexport interface DocxTranslationData {\n  originalText: string\n  translatedText: string\n  sourceLang: string\n  targetLang: string\n  segments: DocxProcessingResult['segments']\n  metadata: DocxProcessingResult['metadata']\n}\n\nexport class DocxProcessor {\n  async validateDocx(buffer: Buffer): Promise<boolean> {\n    try {\n      const fileType = await fileTypeFromBuffer(buffer)\n      return fileType?.mime === 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'\n    } catch (error) {\n      return false\n    }\n  }\n\n  async extractText(buffer: Buffer): Promise<DocxProcessingResult> {\n    try {\n      // Validate DOCX first\n      if (!await this.validateDocx(buffer)) {\n        throw new Error('Invalid DOCX file')\n      }\n\n      // Extract text and HTML using mammoth\n      const textResult = await mammoth.extractRawText({ buffer })\n      const htmlResult = await mammoth.convertToHtml({ buffer })\n\n      const text = textResult.value\n      const html = htmlResult.value\n\n      // Calculate metadata\n      const wordCount = text.split(/\\s+/).filter(word => word.length > 0).length\n      const characterCount = text.length\n\n      // Parse HTML to extract segments (simplified)\n      const segments = this.parseHtmlToSegments(html)\n\n      return {\n        text,\n        html,\n        metadata: {\n          wordCount,\n          characterCount\n        },\n        segments\n      }\n    } catch (error) {\n      console.error('DOCX text extraction error:', error)\n      throw new Error(`Failed to extract text from DOCX: ${error instanceof Error ? error.message : 'Unknown error'}`)\n    }\n  }\n\n  private parseHtmlToSegments(html: string): Array<{ text: string; type: 'paragraph' | 'heading' | 'list'; level?: number }> {\n    const segments: Array<{ text: string; type: 'paragraph' | 'heading' | 'list'; level?: number }> = []\n    \n    // Simple HTML parsing to extract structure\n    // This is a basic implementation - in production you'd use a proper HTML parser\n    const lines = html.split('\\n').filter(line => line.trim())\n    \n    for (const line of lines) {\n      const trimmed = line.trim()\n      \n      if (trimmed.startsWith('<h1>')) {\n        const text = trimmed.replace(/<\\/?h1>/g, '')\n        if (text) segments.push({ text, type: 'heading', level: 1 })\n      } else if (trimmed.startsWith('<h2>')) {\n        const text = trimmed.replace(/<\\/?h2>/g, '')\n        if (text) segments.push({ text, type: 'heading', level: 2 })\n      } else if (trimmed.startsWith('<h3>')) {\n        const text = trimmed.replace(/<\\/?h3>/g, '')\n        if (text) segments.push({ text, type: 'heading', level: 3 })\n      } else if (trimmed.startsWith('<p>')) {\n        const text = trimmed.replace(/<\\/?p>/g, '').replace(/<[^>]*>/g, '')\n        if (text) segments.push({ text, type: 'paragraph' })\n      } else if (trimmed.startsWith('<li>')) {\n        const text = trimmed.replace(/<\\/?li>/g, '').replace(/<[^>]*>/g, '')\n        if (text) segments.push({ text, type: 'list' })\n      }\n    }\n    \n    // If no segments found, create paragraphs from plain text\n    if (segments.length === 0) {\n      const paragraphs = html.replace(/<[^>]*>/g, '').split('\\n\\n').filter(p => p.trim())\n      segments.push(...paragraphs.map(text => ({ text: text.trim(), type: 'paragraph' as const })))\n    }\n    \n    return segments\n  }\n\n  async createTranslatedDocx(translationData: DocxTranslationData): Promise<Buffer> {\n    try {\n      // Create paragraphs from translated segments\n      const paragraphs: Paragraph[] = []\n      \n      // Split translated text back into segments\n      const translatedSegments = this.splitTranslatedText(\n        translationData.translatedText, \n        translationData.segments\n      )\n\n      for (let i = 0; i < translatedSegments.length; i++) {\n        const segment = translatedSegments[i]\n        const originalSegment = translationData.segments[i]\n        \n        if (!segment.trim()) continue\n        \n        let paragraph: Paragraph\n        \n        if (originalSegment?.type === 'heading') {\n          // Create heading paragraph\n          paragraph = new Paragraph({\n            children: [\n              new TextRun({\n                text: segment,\n                bold: true,\n                size: originalSegment.level === 1 ? 32 : originalSegment.level === 2 ? 28 : 24,\n              }),\n            ],\n            spacing: { after: 200 },\n          })\n        } else if (originalSegment?.type === 'list') {\n          // Create list item paragraph\n          paragraph = new Paragraph({\n            children: [\n              new TextRun({\n                text: `â€¢ ${segment}`,\n              }),\n            ],\n            spacing: { after: 100 },\n            indent: { left: 720 }, // 0.5 inch indent\n          })\n        } else {\n          // Create regular paragraph\n          paragraph = new Paragraph({\n            children: [\n              new TextRun({\n                text: segment,\n              }),\n            ],\n            spacing: { after: 150 },\n          })\n        }\n        \n        paragraphs.push(paragraph)\n      }\n\n      // If no structured segments, create simple paragraphs\n      if (paragraphs.length === 0) {\n        const simpleParagraphs = translationData.translatedText\n          .split('\\n\\n')\n          .filter(p => p.trim())\n          .map(text => new Paragraph({\n            children: [new TextRun({ text: text.trim() })],\n            spacing: { after: 150 },\n          }))\n        \n        paragraphs.push(...simpleParagraphs)\n      }\n\n      // Create document\n      const doc = new Document({\n        sections: [\n          {\n            properties: {},\n            children: paragraphs,\n          },\n        ],\n      })\n\n      // Generate buffer\n      const buffer = await Packer.toBuffer(doc)\n      return buffer\n      \n    } catch (error) {\n      console.error('DOCX creation error:', error)\n      throw new Error(`Failed to create translated DOCX: ${error instanceof Error ? error.message : 'Unknown error'}`)\n    }\n  }\n\n  private splitTranslatedText(translatedText: string, originalSegments: DocxProcessingResult['segments']): string[] {\n    // Simple text splitting based on original segment count\n    // In practice, you'd want more sophisticated alignment\n    \n    if (originalSegments.length === 0) {\n      return translatedText.split('\\n\\n').filter(p => p.trim())\n    }\n    \n    // Split by double newlines first\n    const paragraphs = translatedText.split('\\n\\n').filter(p => p.trim())\n    \n    if (paragraphs.length >= originalSegments.length) {\n      return paragraphs.slice(0, originalSegments.length)\n    }\n    \n    // If we have fewer translated paragraphs than original segments,\n    // split the text more aggressively\n    const avgCharsPerSegment = Math.ceil(translatedText.length / originalSegments.length)\n    const segments: string[] = []\n    \n    let remaining = translatedText\n    for (let i = 0; i < originalSegments.length - 1; i++) {\n      if (remaining.length <= avgCharsPerSegment) {\n        segments.push(remaining)\n        remaining = ''\n        break\n      }\n      \n      // Find a good breaking point (sentence or paragraph end)\n      let breakPoint = avgCharsPerSegment\n      const sentenceEnd = remaining.lastIndexOf('.', breakPoint)\n      const paragraphEnd = remaining.lastIndexOf('\\n', breakPoint)\n      \n      if (sentenceEnd > breakPoint * 0.7) {\n        breakPoint = sentenceEnd + 1\n      } else if (paragraphEnd > breakPoint * 0.7) {\n        breakPoint = paragraphEnd + 1\n      }\n      \n      segments.push(remaining.substring(0, breakPoint).trim())\n      remaining = remaining.substring(breakPoint).trim()\n    }\n    \n    if (remaining) {\n      segments.push(remaining)\n    }\n    \n    return segments\n  }\n\n  async getDocumentInfo(buffer: Buffer): Promise<{ wordCount: number; fileSize: number; isValid: boolean }> {\n    try {\n      const isValid = await this.validateDocx(buffer)\n      if (!isValid) {\n        return { wordCount: 0, fileSize: buffer.length, isValid: false }\n      }\n\n      const result = await mammoth.extractRawText({ buffer })\n      const wordCount = result.value.split(/\\s+/).filter(word => word.length > 0).length\n      \n      return {\n        wordCount,\n        fileSize: buffer.length,\n        isValid: true\n      }\n    } catch (error) {\n      return { wordCount: 0, fileSize: buffer.length, isValid: false }\n    }\n  }\n}"
    },
    "output": "",
    "metadata": {
      "diagnostics": {},
      "filepath": "/home/user/project/lib/document-processors/docx-processor.ts",
      "exists": false
    },
    "title": "lib/document-processors/docx-processor.ts",
    "time": {
      "start": 1759477119839,
      "end": 1759477119841
    }
  }
}
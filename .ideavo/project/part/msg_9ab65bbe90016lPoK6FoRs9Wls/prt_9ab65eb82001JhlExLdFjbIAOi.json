{
  "id": "prt_9ab65eb82001JhlExLdFjbIAOi",
  "messageID": "msg_9ab65bbe90016lPoK6FoRs9Wls",
  "sessionID": "ses_65b8a18f2ffeMlgQ4UP0yHPHsm",
  "type": "tool",
  "tool": "webfetch",
  "callID": "toolu_01GpRYi7VTSKrL7LDHYWCAUG",
  "state": {
    "status": "completed",
    "input": {
      "url": "https://help.aliyun.com/zh/dashscope/developer-reference/compatibility-of-openai-with-dashscope",
      "format": "text"
    },
    "output": "使用OpenAI Chat兼容接口调用通义千问_大模型服务平台百炼(Model Studio)-阿里云帮助中心\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n  \n  \n\n\n\n大模型产品解决方案文档与社区权益中心定价云市场合作伙伴支持与服务了解阿里云HOT查看 “” 全部搜索结果AI 助理备案控制台\n\n  官方文档输入文档关键字查找\n大模型服务平台百炼\n\n \n\n\n用户指南（模型）\n\n\n \n\n\n用户指南（应用）\n\n\n \n\n\nAPI参考（模型）\n\n\n \n\n\nAPI参考（应用）\n\n\n \n\n\n历史文档\n\n\n\n首页\n \n\n\n 大模型服务平台百炼\n \n\n\n API参考（模型）\n \n\n\n 工具包/框架\n \n\n\n OpenAI兼容-Chat\nOpenAI Chat接口兼容更新时间：产品详情我的收藏\n阿里云百炼的通义千问模型支持 OpenAI 兼容接口，您只需调整 API Key、BASE_URL 和模型名称，即可将原有 OpenAI 代码迁移至阿里云百炼服务使用。兼容OpenAI需要信息BASE_URLBASE_URL表示模型服务的网络访问点或地址。通过该地址，您可以访问服务提供的功能或数据。在Web服务或API的使用中，BASE_URL通常对应于服务的具体操作或资源的URL。当您使用OpenAI兼容接口来使用阿里云百炼模型服务时，需要配置BASE_URL。当您通过OpenAI SDK或其他OpenAI兼容的SDK调用时，需要配置的BASE_URL如下：北京：https://dashscope.aliyuncs.com/compatible-mode/v1\n新加坡：https://dashscope-intl.aliyuncs.com/compatible-mode/v1当您通过HTTP请求调用时，需要配置的完整访问endpoint如下：北京：POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\n新加坡：POST https://dashscope-intl.aliyuncs.com/compatible-mode/v1/chat/completions支持的模型列表当前OpenAI兼容接口支持的通义千问系列模型如下表所示。模型分类模型名称通义千问qwen-longqwq-plusqwq-plus-latestqwq-plus-2025-03-05qwen-maxqwen-max-latestqwen-max-2025-01-25qwen-max-2024-09-19qwen-max-2024-04-28qwen-max-2024-04-03qwen-plusqwen-plus-latestqwen-plus-2025-04-28qwen-plus-2025-01-25qwen-plus-2025-01-12qwen-plus-2024-11-27qwen-plus-2024-11-25qwen-plus-2024-09-19qwen-plus-2024-08-06qwen-plus-2024-07-23qwen-turboqwen-turbo-latestqwen-turbo-2025-04-28qwen-turbo-2025-02-11qwen-turbo-2024-11-01qwen-turbo-2024-09-19qwen-turbo-2024-06-24qwen-math-plusqwen-math-plus-latestqwen-math-plus-2024-09-19qwen-math-plus-2024-08-16qwen-math-turboqwen-math-turbo-latestqwen-math-turbo-2024-09-19qwen-coder-plusqwen-coder-plus-latestqwen-coder-plus-2024-11-06qwen-coder-turboqwen-coder-turbo-latestqwen-coder-turbo-2024-09-19通义千问开源系列qwq-32bqwq-32b-previewqwen3-235b-a22bqwen3-32bqwen3-30b-a3bqwen3-14bqwen3-8bqwen3-4bqwen3-1.7bqwen3-0.6bqwen2.5-14b-instruct-1mqwen2.5-7b-instruct-1mqwen2.5-72b-instructqwen2.5-32b-instructqwen2.5-14b-instructqwen2.5-7b-instructqwen2.5-3b-instructqwen2.5-1.5b-instructqwen2.5-0.5b-instructqwen2.5-math-72b-instructqwen2.5-math-7b-instructqwen2.5-math-1.5b-instructqwen2.5-coder-32b-instructqwen2.5-coder-14b-instructqwen2.5-coder-7b-instructqwen2.5-coder-3b-instructqwen2.5-coder-1.5b-instructqwen2.5-coder-0.5b-instructqwen2-57b-a14b-instructqwen2-72b-instructqwen2-7b-instructqwen2-1.5b-instructqwen2-0.5b-instructqwen1.5-110b-chatqwen1.5-72b-chatqwen1.5-32b-chatqwen1.5-14b-chatqwen1.5-7b-chatqwen1.5-1.8b-chatqwen1.5-0.5b-chatcodeqwen1.5-7b-chat通过OpenAI SDK调用前提条件请确保您的计算机上安装了Python环境。请安装最新版OpenAI SDK。# 如果下述命令报错，请将pip替换为pip3\npip install -U openai您需要开通阿里云百炼模型服务并获得API-KEY，详情请参考：获取API Key。我们推荐您将API-KEY配置到环境变量中以降低API-KEY的泄露风险，配置方法可参考配置API Key到环境变量。您也可以在代码中配置API-KEY，但是泄露风险会提高。请选择您需要使用的模型：支持的模型列表。使用方式您可以参考以下示例来使用OpenAI SDK访问百炼服务上的通义千问模型。非流式调用示例from openai import OpenAI\nimport os\n\ndef get_response():\n    client = OpenAI(\n        # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key=\"sk-xxx\",\n        # 新加坡和北京地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key\n        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n        # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n    )\n    completion = client.chat.completions.create(\n        model=\"qwen-plus\",  # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n        messages=[{'role': 'system', 'content': 'You are a helpful assistant.'},\n                  {'role': 'user', 'content': '你是谁？'}]\n        )\n    print(completion.model_dump_json())\n\nif __name__ == '__main__':\n    get_response()运行代码可以获得以下结果：{\n    \"id\": \"chatcmpl-xxx\",\n    \"choices\": [\n        {\n            \"finish_reason\": \"stop\",\n            \"index\": 0,\n            \"logprobs\": null,\n            \"message\": {\n                \"content\": \"我是来自阿里云的超大规模预训练模型，我叫通义千问。\",\n                \"role\": \"assistant\",\n                \"function_call\": null,\n                \"tool_calls\": null\n            }\n        }\n    ],\n    \"created\": 1716430652,\n    \"model\": \"qwen-plus\",\n    \"object\": \"chat.completion\",\n    \"system_fingerprint\": null,\n    \"usage\": {\n        \"completion_tokens\": 18,\n        \"prompt_tokens\": 22,\n        \"total_tokens\": 40\n    }\n}流式调用示例from openai import OpenAI\nimport os\n\n\ndef get_response():\n    client = OpenAI(\n        # 如果您没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key=\"sk-xxx\"\n        # 新加坡和北京地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key\n        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n        # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n    )\n    completion = client.chat.completions.create(\n        model=\"qwen-plus\",  # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n        messages=[{'role': 'system', 'content': 'You are a helpful assistant.'},\n                  {'role': 'user', 'content': '你是谁？'}],\n        stream=True,\n        # 通过以下设置，在流式输出的最后一行展示token使用信息\n        stream_options={\"include_usage\": True}\n        )\n    for chunk in completion:\n        print(chunk.model_dump_json())\n\n\nif __name__ == '__main__':\n    get_response()\n运行代码可以获得以下结果：{\"id\":\"chatcmpl-xxx\",\"choices\":[{\"delta\":{\"content\":\"\",\"function_call\":null,\"role\":\"assistant\",\"tool_calls\":null},\"finish_reason\":null,\"index\":0,\"logprobs\":null}],\"created\":1719286190,\"model\":\"qwen-plus\",\"object\":\"chat.completion.chunk\",\"system_fingerprint\":null,\"usage\":null}\n{\"id\":\"chatcmpl-xxx\",\"choices\":[{\"delta\":{\"content\":\"我是\",\"function_call\":null,\"role\":null,\"tool_calls\":null},\"finish_reason\":null,\"index\":0,\"logprobs\":null}],\"created\":1719286190,\"model\":\"qwen-plus\",\"object\":\"chat.completion.chunk\",\"system_fingerprint\":null,\"usage\":null}\n{\"id\":\"chatcmpl-xxx\",\"choices\":[{\"delta\":{\"content\":\"来自\",\"function_call\":null,\"role\":null,\"tool_calls\":null},\"finish_reason\":null,\"index\":0,\"logprobs\":null}],\"created\":1719286190,\"model\":\"qwen-plus\",\"object\":\"chat.completion.chunk\",\"system_fingerprint\":null,\"usage\":null}\n{\"id\":\"chatcmpl-xxx\",\"choices\":[{\"delta\":{\"content\":\"阿里\",\"function_call\":null,\"role\":null,\"tool_calls\":null},\"finish_reason\":null,\"index\":0,\"logprobs\":null}],\"created\":1719286190,\"model\":\"qwen-plus\",\"object\":\"chat.completion.chunk\",\"system_fingerprint\":null,\"usage\":null}\n{\"id\":\"chatcmpl-xxx\",\"choices\":[{\"delta\":{\"content\":\"云的大规模语言模型\",\"function_call\":null,\"role\":null,\"tool_calls\":null},\"finish_reason\":null,\"index\":0,\"logprobs\":null}],\"created\":1719286190,\"model\":\"qwen-plus\",\"object\":\"chat.completion.chunk\",\"system_fingerprint\":null,\"usage\":null}\n{\"id\":\"chatcmpl-xxx\",\"choices\":[{\"delta\":{\"content\":\"，我叫通义千问。\",\"function_call\":null,\"role\":null,\"tool_calls\":null},\"finish_reason\":null,\"index\":0,\"logprobs\":null}],\"created\":1719286190,\"model\":\"qwen-plus\",\"object\":\"chat.completion.chunk\",\"system_fingerprint\":null,\"usage\":null}\n{\"id\":\"chatcmpl-xxx\",\"choices\":[{\"delta\":{\"content\":\"\",\"function_call\":null,\"role\":null,\"tool_calls\":null},\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null}],\"created\":1719286190,\"model\":\"qwen-plus\",\"object\":\"chat.completion.chunk\",\"system_fingerprint\":null,\"usage\":null}\n{\"id\":\"chatcmpl-xxx\",\"choices\":[],\"created\":1719286190,\"model\":\"qwen-plus\",\"object\":\"chat.completion.chunk\",\"system_fingerprint\":null,\"usage\":{\"completion_tokens\":16,\"prompt_tokens\":22,\"total_tokens\":38}}function call示例此处以天气查询工具与时间查询工具为例，向您展示通过OpenAI接口兼容实现function call的功能。示例代码可以实现多轮工具调用。from openai import OpenAI\nfrom datetime import datetime\nimport json\nimport os\n\nclient = OpenAI(\n    # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key=\"sk-xxx\",\n    # 新加坡和北京地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key\n    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n    # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1\n    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",  # 填写DashScope SDK的base_url\n)\n\n# 定义工具列表，模型在选择使用哪个工具时会参考工具的name和description\ntools = [\n    # 工具1 获取当前时刻的时间\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_current_time\",\n            \"description\": \"当你想知道现在的时间时非常有用。\",\n            # 因为获取当前时间无需输入参数，因此parameters为空字典\n            \"parameters\": {}\n        }\n    },\n    # 工具2 获取指定城市的天气\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_current_weather\",\n            \"description\": \"当你想查询指定城市的天气时非常有用。\",\n            \"parameters\": { \n                \"type\": \"object\",\n                \"properties\": {\n                    # 查询天气时需要提供位置，因此参数设置为location\n                    \"location\": {\n                        \"type\": \"string\",\n                        \"description\": \"城市或县区，比如北京市、杭州市、余杭区等。\"\n                    }\n                }\n            },\n            \"required\": [\n                \"location\"\n            ]\n        }\n    }\n]\n\n# 模拟天气查询工具。返回结果示例：“北京今天是雨天。”\ndef get_current_weather(location):\n    return f\"{location}今天是雨天。 \"\n\n# 查询当前时间的工具。返回结果示例：“当前时间：2024-04-15 17:15:18。“\ndef get_current_time():\n    # 获取当前日期和时间\n    current_datetime = datetime.now()\n    # 格式化当前日期和时间\n    formatted_time = current_datetime.strftime('%Y-%m-%d %H:%M:%S')\n    # 返回格式化后的当前时间\n    return f\"当前时间：{formatted_time}。\"\n\n# 封装模型响应函数\ndef get_response(messages):\n    completion = client.chat.completions.create(\n        model=\"qwen-plus\",  # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n        messages=messages,\n        tools=tools\n        )\n    return completion.model_dump()\n\ndef call_with_messages():\n    print('\\n')\n    messages = [\n            {\n                \"content\": input('请输入：'),  # 提问示例：\"现在几点了？\" \"一个小时后几点\" \"北京天气如何？\"\n                \"role\": \"user\"\n            }\n    ]\n    print(\"-\"*60)\n    # 模型的第一轮调用\n    i = 1\n    first_response = get_response(messages)\n    assistant_output = first_response['choices'][0]['message']\n    print(f\"\\n第{i}轮大模型输出信息：{first_response}\\n\")\n    if  assistant_output['content'] is None:\n        assistant_output['content'] = \"\"\n    messages.append(assistant_output)\n    # 如果不需要调用工具，则直接返回最终答案\n    if assistant_output['tool_calls'] == None:  # 如果模型判断无需调用工具，则将assistant的回复直接打印出来，无需进行模型的第二轮调用\n        print(f\"无需调用工具，我可以直接回复：{assistant_output['content']}\")\n        return\n    # 如果需要调用工具，则进行模型的多轮调用，直到模型判断无需调用工具\n    while assistant_output['tool_calls'] != None:\n        # 如果判断需要调用查询天气工具，则运行查询天气工具\n        if assistant_output['tool_calls'][0]['function']['name'] == 'get_current_weather':\n            tool_info = {\"name\": \"get_current_weather\", \"role\":\"tool\"}\n            # 提取位置参数信息\n            location = json.loads(assistant_output['tool_calls'][0]['function']['arguments'])['location']\n            tool_info['content'] = get_current_weather(location)\n        # 如果判断需要调用查询时间工具，则运行查询时间工具\n        elif assistant_output['tool_calls'][0]['function']['name'] == 'get_current_time':\n            tool_info = {\"name\": \"get_current_time\", \"role\":\"tool\"}\n            tool_info['content'] = get_current_time()\n        print(f\"工具输出信息：{tool_info['content']}\\n\")\n        print(\"-\"*60)\n        messages.append(tool_info)\n        assistant_output = get_response(messages)['choices'][0]['message']\n        if  assistant_output['content'] is None:\n            assistant_output['content'] = \"\"\n        messages.append(assistant_output)\n        i += 1\n        print(f\"第{i}轮大模型输出信息：{assistant_output}\\n\")\n    print(f\"最终答案：{assistant_output['content']}\")\n\nif __name__ == '__main__':\n    call_with_messages()当输入：杭州和北京天气怎么样？现在几点了？时，程序会进行如下输出：输入参数配置输入参数与OpenAI的接口参数对齐，当前已支持的参数如下：参数类型默认值说明modelstring-用户使用model参数指明对应的模型，可选的模型请见支持的模型列表。messagesarray-用户与模型的对话历史。array中的每个元素形式为{\"role\":角色, \"content\": 内容}。角色当前可选值：system、user、assistant，其中，仅messages[0]中支持role为system，一般情况下，user和assistant需要交替出现，且messages中最后一个元素的role必须为user。top_p（可选） float-生成过程中的核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越小，生成的确定性越高。temperature（可选）float-用于控制模型回复的随机性和多样性。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。取值范围： [0, 2)，不建议取值为0，无意义。presence_penalty（可选）float-用户控制模型生成时整个序列中的重复度。提高presence_penalty时可以降低模型生成的重复度，取值范围[-2.0, 2.0]。说明 目前仅在千问商业模型和qwen1.5及以后的开源模型上支持该参数。n（可选）integer1生成响应的个数，取值范围是1-4。对于需要生成多个响应的场景（如创意写作、广告文案等），可以设置较大的 n 值。设置较大的 n 值不会增加输入 Token 消耗，会增加输出 Token 的消耗。当前仅支持 qwen-plus 模型，且在传入 tools 参数时固定为1。max_tokens（可选）integer-指定模型可生成的最大token个数。例如模型最大输出长度为2k，您可以设置为1k，防止模型输出过长的内容。不同的模型有不同的输出上限，具体请参见模型列表。seed（可选）integer-生成时使用的随机数种子，用于控制模型生成内容的随机性。seed支持无符号64位整数。stream（可选） booleanFalse用于控制是否使用流式输出。当以stream模式输出结果时，接口返回结果为generator，需要通过迭代获取结果，每次输出为当前生成的增量序列。stop（可选） string or arrayNonestop参数用于实现内容生成过程的精确控制，在模型生成的内容即将包含指定的字符串或token_id时自动停止。stop可以为string类型或array类型。string类型当模型将要生成指定的stop词语时停止。例如将stop指定为\"你好\"，则模型将要生成“你好”时停止。array类型array中的元素可以为token_id或者字符串，或者元素为token_id的array。当模型将要生成的token或其对应的token_id在stop中时，模型生成将会停止。以下为stop为array时的示例（tokenizer对应模型为qwen-turbo）：1.元素为token_id：token_id为108386和104307分别对应token为“你好”和“天气”，设定stop为[108386,104307]，则模型将要生成“你好”或者“天气”时停止。2.元素为字符串：设定stop为[\"你好\",\"天气\"]，则模型将要生成“你好”或者“天气”时停止。3.元素为array：token_id为108386和103924分别对应token为“你好”和“啊”，token_id为35946和101243分别对应token为“我”和“很好”。设定stop为[[108386, 103924],[35946, 101243]]，则模型将要生成“你好啊”或者“我很好”时停止。说明 stop为array类型时，不可以将token_id和字符串同时作为元素输入，比如不可以指定stop为[\"你好\",104307]。tools（可选）arrayNone用于指定可供模型调用的工具库，一次function call流程模型会从中选择其中一个工具。tools中每一个tool的结构如下：type，类型为string，表示tools的类型，当前仅支持function。function，类型为object，键值包括name，description和parameters：name：类型为string，表示工具函数的名称，必须是字母、数字，可以包含下划线和短划线，最大长度为64。description：类型为string，表示工具函数的描述，供模型选择何时以及如何调用工具函数。parameters：类型为object，表示工具的参数描述，需要是一个合法的JSON Schema。JSON Schema的描述可以见链接。如果parameters参数为空，表示function没有入参。在function call流程中，无论是发起function call的轮次，还是向模型提交工具函数的执行结果，均需设置tools参数。当前支持的模型包括qwen-turbo、qwen-plus和qwen-max。说明 tools暂时无法与stream=True同时使用。stream_options（可选）objectNone该参数用于配置在流式输出时是否展示使用的token数目。只有当stream为True的时候该参数才会激活生效。若您需要统计流式输出模式下的token数目，可将该参数配置为stream_options={\"include_usage\":True}。enable_searchbooleanFalse用于控制模型在生成文本时是否使用互联网搜索结果进行参考。取值如下：True：启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑判断是否使用互联网搜索结果。如果模型没有搜索互联网，建议优化Prompt，或设置search_options中的forced_search参数开启强制搜索。False（默认）：关闭互联网搜索。qwen-long暂不支持此参数。配置方式为：extra_body={\"enable_search\": True}。返回参数说明返回参数数据类型说明备注idstring系统生成的标识本次调用的id。无modelstring本次调用的模型名。无system_fingerprintstring模型运行时使用的配置版本，当前暂时不支持，返回为空字符串“”。无choicesarray模型生成内容的详情。无choices[i].finish_reasonstring有三种情况：正在生成时为null；因触发输入参数中的stop条件而结束为stop；因生成长度过长而结束为length。choices[i].messageobject模型输出的消息。choices[i].message.rolestring模型的角色，固定为assistant。choices[i].message.contentstring模型生成的文本。choices[i].indexinteger生成的结果序列编号，默认为0。createdinteger当前生成结果的时间戳（s）。无usageobject计量信息，表示本次请求所消耗的token数据。无usage.prompt_tokensinteger用户输入文本转换成token后的长度。无usage.completion_tokensinteger模型生成回复转换为token后的长度。无usage.total_tokensintegerusage.prompt_tokens与usage.completion_tokens的总和。无通过langchain_openai SDK调用前提条件请确保您的计算机上安装了Python环境。通过运行以下命令安装langchain_openai SDK。# 如果下述命令报错，请将pip替换为pip3\npip install -U langchain_openai您需要开通阿里云百炼模型服务并获得API-KEY，详情请参考：获取API Key。我们推荐您将API-KEY配置到环境变量中以降低API-KEY的泄露风险，详情可参考配置API Key到环境变量。您也可以在代码中配置API-KEY，但是泄露风险会提高。请选择您需要使用的模型：支持的模型列表。使用方式您可以参考以下示例来通过langchain_openai SDK使用阿里云百炼的千问模型。非流式输出非流式输出使用invoke方法实现，请参考以下示例代码：from langchain_openai import ChatOpenAI\nimport os\n\ndef get_response():\n    llm = ChatOpenAI(\n        # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key=\"sk-xxx\",\n        # 新加坡和北京地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key\n        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n        # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n        model=\"qwen-plus\"    # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n        )\n    messages = [\n        {\"role\":\"system\",\"content\":\"You are a helpful assistant.\"}, \n        {\"role\":\"user\",\"content\":\"你是谁？\"}\n    ]\n    response = llm.invoke(messages)\n    print(response.json())\n\nif __name__ == \"__main__\":\n    get_response()运行代码，可以得到以下结果：{\n    \"content\": \"我是来自阿里云的大规模语言模型，我叫通义千问。\",\n    \"additional_kwargs\": {},\n    \"response_metadata\": {\n        \"token_usage\": {\n            \"completion_tokens\": 16,\n            \"prompt_tokens\": 22,\n            \"total_tokens\": 38\n        },\n        \"model_name\": \"qwen-plus\",\n        \"system_fingerprint\": \"\",\n        \"finish_reason\": \"stop\",\n        \"logprobs\": null\n    },\n    \"type\": \"ai\",\n    \"name\": null,\n    \"id\": \"run-xxx\",\n    \"example\": false,\n    \"tool_calls\": [],\n    \"invalid_tool_calls\": []\n}流式输出流式输出使用stream方法实现，无需在参数中配置stream参数。from langchain_openai import ChatOpenAI\nimport os\n\ndef get_response():\n    llm = ChatOpenAI(\n        # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key=\"sk-xxx\",\n        # 新加坡和北京地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key\n        api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n        # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\", \n        model=\"qwen-plus\",  # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n        stream_usage=True\n        )\n    messages = [\n        {\"role\":\"system\",\"content\":\"You are a helpful assistant.\"}, \n        {\"role\":\"user\",\"content\":\"你是谁？\"},\n    ]\n    response = llm.stream(messages)\n    for chunk in response:\n        print(chunk.model_dump_json())\n\nif __name__ == \"__main__\":\n    get_response()运行代码，可以得到以下结果：{\"content\": \"\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"AIMessageChunk\", \"name\": null, \"id\": \"run-xxx\", \"example\": false, \"tool_calls\": [], \"invalid_tool_calls\": [], \"usage_metadata\": null, \"tool_call_chunks\": []}\n{\"content\": \"我是\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"AIMessageChunk\", \"name\": null, \"id\": \"run-xxx\", \"example\": false, \"tool_calls\": [], \"invalid_tool_calls\": [], \"usage_metadata\": null, \"tool_call_chunks\": []}\n{\"content\": \"来自\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"AIMessageChunk\", \"name\": null, \"id\": \"run-xxx\", \"example\": false, \"tool_calls\": [], \"invalid_tool_calls\": [], \"usage_metadata\": null, \"tool_call_chunks\": []}\n{\"content\": \"阿里\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"AIMessageChunk\", \"name\": null, \"id\": \"run-xxx\", \"example\": false, \"tool_calls\": [], \"invalid_tool_calls\": [], \"usage_metadata\": null, \"tool_call_chunks\": []}\n{\"content\": \"云\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"AIMessageChunk\", \"name\": null, \"id\": \"run-xxx\", \"example\": false, \"tool_calls\": [], \"invalid_tool_calls\": [], \"usage_metadata\": null, \"tool_call_chunks\": []}\n{\"content\": \"的大规模语言模型\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"AIMessageChunk\", \"name\": null, \"id\": \"run-xxx\", \"example\": false, \"tool_calls\": [], \"invalid_tool_calls\": [], \"usage_metadata\": null, \"tool_call_chunks\": []}\n{\"content\": \"，我叫通\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"AIMessageChunk\", \"name\": null, \"id\": \"run-xxx\", \"example\": false, \"tool_calls\": [], \"invalid_tool_calls\": [], \"usage_metadata\": null, \"tool_call_chunks\": []}\n{\"content\": \"义千问。\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"AIMessageChunk\", \"name\": null, \"id\": \"run-xxx\", \"example\": false, \"tool_calls\": [], \"invalid_tool_calls\": [], \"usage_metadata\": null, \"tool_call_chunks\": []}\n{\"content\": \"\", \"additional_kwargs\": {}, \"response_metadata\": {\"finish_reason\": \"stop\"}, \"type\": \"AIMessageChunk\", \"name\": null, \"id\": \"run-xxx\", \"example\": false, \"tool_calls\": [], \"invalid_tool_calls\": [], \"usage_metadata\": null, \"tool_call_chunks\": []}\n{\"content\": \"\", \"additional_kwargs\": {}, \"response_metadata\": {}, \"type\": \"AIMessageChunk\", \"name\": null, \"id\": \"run-xxx\", \"example\": false, \"tool_calls\": [], \"invalid_tool_calls\": [], \"usage_metadata\": {\"input_tokens\": 22, \"output_tokens\": 16, \"total_tokens\": 38}, \"tool_call_chunks\": []}关于输入参数的配置，可以参考输入参数配置，相关参数在ChatOpenAI对象中定义。通过HTTP接口调用您可以通过HTTP接口来调用阿里云百炼服务，获得与通过HTTP接口调用OpenAI服务相同结构的返回结果。前提条件您需要开通阿里云百炼模型服务并获得API-KEY，详情请参考：获取API Key。我们推荐您将API-KEY配置到环境变量中以降低API-KEY的泄露风险，配置方法可参考配置API Key到环境变量。您也可以在代码中配置API-KEY，但是泄露风险会提高。提交接口调用北京：POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions\n新加坡：POST https://dashscope-intl.aliyuncs.com/compatible-mode/v1/chat/completions请求示例以下示例展示通过cURL命令来调用API的脚本。说明 如果您没有配置API-KEY为环境变量，需将$DASHSCOPE_API_KEY更改为您的API-KEY。非流式输出curl# ======= 重要提示 =======\n# 新加坡和北京地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key\n# 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1/chat/completions\n# === 执行时请删除该注释 ===\ncurl --location 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions' \\\n--header \"Authorization: Bearer $DASHSCOPE_API_KEY\" \\\n--header 'Content-Type: application/json' \\\n--data '{\n    \"model\": \"qwen-plus\",  \n    \"messages\": [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful assistant.\"\n        },\n        {\n            \"role\": \"user\", \n            \"content\": \"你是谁？\"\n        }\n    ]\n}'\n运行命令可得到以下结果：{\n    \"choices\": [\n        {\n            \"message\": {\n                \"role\": \"assistant\",\n                \"content\": \"我是来自阿里云的大规模语言模型，我叫通义千问。\"\n            },\n            \"finish_reason\": \"stop\",\n            \"index\": 0,\n            \"logprobs\": null\n        }\n    ],\n    \"object\": \"chat.completion\",\n    \"usage\": {\n        \"prompt_tokens\": 11,\n        \"completion_tokens\": 16,\n        \"total_tokens\": 27\n    },\n    \"created\": 1715252778,\n    \"system_fingerprint\": \"\",\n    \"model\": \"qwen-plus\",\n    \"id\": \"chatcmpl-xxx\"\n}流式输出如果您需要使用流式输出，请在请求体中指定stream参数为true。# ======= 重要提示 =======\n# 新加坡和北京地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key\n# 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1/chat/completions\n# === 执行时请删除该注释 ===\ncurl --location 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions' \\\n--header \"Authorization: Bearer $DASHSCOPE_API_KEY\" \\\n--header 'Content-Type: application/json' \\\n--data '{\n    \"model\": \"qwen-plus\",  \n    \"messages\": [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful assistant.\"\n        },\n        {\n            \"role\": \"user\", \n            \"content\": \"你是谁？\"\n        }\n    ],\n    \"stream\":true\n}'运行命令可得到以下结果：data: {\"choices\":[{\"delta\":{\"content\":\"\",\"role\":\"assistant\"},\"index\":0,\"logprobs\":null,\"finish_reason\":null}],\"object\":\"chat.completion.chunk\",\"usage\":null,\"created\":1715931028,\"system_fingerprint\":null,\"model\":\"qwen-plus\",\"id\":\"chatcmpl-3bb05cf5cd819fbca5f0b8d67a025022\"}\n\ndata: {\"choices\":[{\"finish_reason\":null,\"delta\":{\"content\":\"我是\"},\"index\":0,\"logprobs\":null}],\"object\":\"chat.completion.chunk\",\"usage\":null,\"created\":1715931028,\"system_fingerprint\":null,\"model\":\"qwen-plus\",\"id\":\"chatcmpl-3bb05cf5cd819fbca5f0b8d67a025022\"}\n\ndata: {\"choices\":[{\"delta\":{\"content\":\"来自\"},\"finish_reason\":null,\"index\":0,\"logprobs\":null}],\"object\":\"chat.completion.chunk\",\"usage\":null,\"created\":1715931028,\"system_fingerprint\":null,\"model\":\"qwen-plus\",\"id\":\"chatcmpl-3bb05cf5cd819fbca5f0b8d67a025022\"}\n\ndata: {\"choices\":[{\"delta\":{\"content\":\"阿里\"},\"finish_reason\":null,\"index\":0,\"logprobs\":null}],\"object\":\"chat.completion.chunk\",\"usage\":null,\"created\":1715931028,\"system_fingerprint\":null,\"model\":\"qwen-plus\",\"id\":\"chatcmpl-3bb05cf5cd819fbca5f0b8d67a025022\"}\n\ndata: {\"choices\":[{\"delta\":{\"content\":\"云的大规模语言模型\"},\"finish_reason\":null,\"index\":0,\"logprobs\":null}],\"object\":\"chat.completion.chunk\",\"usage\":null,\"created\":1715931028,\"system_fingerprint\":null,\"model\":\"qwen-plus\",\"id\":\"chatcmpl-3bb05cf5cd819fbca5f0b8d67a025022\"}\n\ndata: {\"choices\":[{\"delta\":{\"content\":\"，我叫通义千问。\"},\"finish_reason\":null,\"index\":0,\"logprobs\":null}],\"object\":\"chat.completion.chunk\",\"usage\":null,\"created\":1715931028,\"system_fingerprint\":null,\"model\":\"qwen-plus\",\"id\":\"chatcmpl-3bb05cf5cd819fbca5f0b8d67a025022\"}\n\ndata: {\"choices\":[{\"delta\":{\"content\":\"\"},\"finish_reason\":\"stop\",\"index\":0,\"logprobs\":null}],\"object\":\"chat.completion.chunk\",\"usage\":null,\"created\":1715931028,\"system_fingerprint\":null,\"model\":\"qwen-plus\",\"id\":\"chatcmpl-3bb05cf5cd819fbca5f0b8d67a025022\"}\n\ndata: [DONE]\n输入参数的详情请参考输入参数配置。异常响应示例在访问请求出错的情况下，输出的结果中会通过 code 和 message 指明出错原因。{\n    \"error\": {\n        \"message\": \"Incorrect API key provided. \",\n        \"type\": \"invalid_request_error\",\n        \"param\": null,\n        \"code\": \"invalid_api_key\"\n    }\n}状态码说明错误码说明400 - Invalid Request Error 输入请求错误，细节请参见具体报错信息。401 - Incorrect API key provided\tAPI key不正确。429 - Rate limit reached for requests\tQPS、QPM等超限。429 - You exceeded your current quota, please check your plan and billing details额度超限或者欠费。500 - The server had an error while processing your request服务端错误。503 - The engine is currently overloaded, please try again later服务端负载过高，可重试。\n\n上一篇：工具包/框架下一篇：OpenAI兼容-Completions该文章对您有帮助吗？反馈\n  为什么选择阿里云什么是云计算全球基础设施技术领先稳定可靠安全合规分析师报告产品和定价全部产品免费试用产品动态产品定价配置报价器云上成本管理解决方案技术解决方案文档与社区文档开发者社区天池大赛培训与认证权益中心免费试用解决方案免费试用高校计划5亿算力补贴推荐返现计划支持与服务基础服务企业增值服务迁云服务官网公告健康看板信任中心关注阿里云关注阿里云公众号或下载阿里云APP，关注云资讯，随时随地运维管控云服务联系我们：4008013260法律声明Cookies政策廉正举报安全举报联系我们加入我们友情链接阿里巴巴集团淘宝网天猫全球速卖通阿里巴巴国际交易市场1688阿里妈妈飞猪阿里云计算AliOS万网高德UC友盟优酷钉钉支付宝达摩院淘宝海外阿里云盘饿了么© 2009-2025 Aliyun.com 版权所有 增值电信业务经营许可证： 浙B2-20080101 域名注册服务机构许可： 浙D3-20210002浙公网安备 33010602009975号浙B2-20080101-4",
    "metadata": {},
    "title": "https://help.aliyun.com/zh/dashscope/developer-reference/compatibility-of-openai-with-dashscope (text/html;charset=UTF-8)",
    "time": {
      "start": 1759517208325,
      "end": 1759517210529
    }
  }
}